{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78c016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NN Risk Summary: Definitions ===\n",
    "import json, os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def safe_write_json(obj, path):\n",
    "    \"\"\"Write JSON safely even if no directory portion exists.\"\"\"\n",
    "    dir_ = os.path.dirname(path)\n",
    "    if dir_:\n",
    "        os.makedirs(dir_, exist_ok=True)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------------\n",
    "# Feature engineering\n",
    "# ----------------------------\n",
    "def prepare_features(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build robust numeric features from the patent events JSON:\n",
    "      - Dates -> calendar features\n",
    "      - linked_reviewers -> count + top-10 one-hots\n",
    "      - reviewer_risk_contributions -> mean/sum/max aggregates\n",
    "      - Categorical basics (patent_type, technology_domain, TC, source) -> one-hot\n",
    "    Returns:\n",
    "      X (numeric DataFrame), y_cont (continuous target), df_full (unaltered copy)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure expected columns exist (as NaN if missing)\n",
    "    base_cols = [\"patent_type\", \"technology_domain\", \"TC\", \"source\"]\n",
    "    for col in base_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # Dates -> numeric calendar features\n",
    "    if \"event_date\" in df.columns:\n",
    "        dt = pd.to_datetime(df[\"event_date\"], errors=\"coerce\")\n",
    "        df[\"event_year\"] = dt.dt.year\n",
    "        df[\"event_month\"] = dt.dt.month\n",
    "        df[\"event_dayofweek\"] = dt.dt.dayofweek\n",
    "        df[\"event_is_month_start\"] = dt.dt.is_month_start.astype(\"float\")\n",
    "        df[\"event_is_month_end\"] = dt.dt.is_month_end.astype(\"float\")\n",
    "\n",
    "    # linked_reviewers -> count + one-hot of top-10 reviewers\n",
    "    if \"linked_reviewers\" in df.columns:\n",
    "        df[\"num_reviewers\"] = df[\"linked_reviewers\"].apply(\n",
    "            lambda x: len(x) if isinstance(x, (list, tuple)) else 0\n",
    "        )\n",
    "        all_rev = []\n",
    "        for v in df[\"linked_reviewers\"]:\n",
    "            if isinstance(v, (list, tuple)):\n",
    "                all_rev.extend(v)\n",
    "        top_reviewers = pd.Series(all_rev).value_counts().head(10).index.tolist() if len(all_rev) else []\n",
    "        for rid in top_reviewers:\n",
    "            df[f\"reviewer_{rid}\"] = df[\"linked_reviewers\"].apply(\n",
    "                lambda x: 1.0 if isinstance(x, (list, tuple)) and rid in x else 0.0\n",
    "            )\n",
    "\n",
    "    # reviewer_risk_contributions -> numeric aggregates\n",
    "    def _agg_reviewer_metrics(lst, key, fn):\n",
    "        if not isinstance(lst, list) or len(lst) == 0:\n",
    "            return np.nan\n",
    "        vals = [d.get(key) for d in lst if isinstance(d, dict) and pd.notna(d.get(key))]\n",
    "        if not vals:\n",
    "            return np.nan\n",
    "        if fn == \"mean\":\n",
    "            return float(np.mean(vals))\n",
    "        if fn == \"sum\":\n",
    "            return float(np.sum(vals))\n",
    "        if fn == \"max\":\n",
    "            return float(np.max(vals))\n",
    "        return np.nan\n",
    "\n",
    "    if \"reviewer_risk_contributions\" in df.columns:\n",
    "        for k in [\"current_rate\", \"past_rate\", \"consistency_score\", \"risk_contribution\"]:\n",
    "            df[f\"rrc_{k}_mean\"] = df[\"reviewer_risk_contributions\"].apply(lambda x: _agg_reviewer_metrics(x, k, \"mean\"))\n",
    "            df[f\"rrc_{k}_sum\"]  = df[\"reviewer_risk_contributions\"].apply(lambda x: _agg_reviewer_metrics(x, k, \"sum\"))\n",
    "            df[f\"rrc_{k}_max\"]  = df[\"reviewer_risk_contributions\"].apply(lambda x: _agg_reviewer_metrics(x, k, \"max\"))\n",
    "\n",
    "    # Target: composite_risk_score (continuous in [0,1])\n",
    "    if \"composite_risk_score\" not in df.columns:\n",
    "        raise ValueError(\"Missing composite_risk_score in data.\")\n",
    "    y_cont = df[\"composite_risk_score\"].astype(float)\n",
    "\n",
    "    # Build feature frame\n",
    "    num_cols = [\n",
    "        \"event_year\", \"event_month\", \"event_dayofweek\", \"event_is_month_start\", \"event_is_month_end\",\n",
    "        \"num_reviewers\"\n",
    "    ]\n",
    "    num_cols += [c for c in df.columns if c.startswith(\"reviewer_\")]\n",
    "    num_cols += [c for c in df.columns if c.startswith(\"rrc_\")]\n",
    "\n",
    "    cat_cols = [c for c in base_cols if c in df.columns]\n",
    "    existing_num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "    X = df[existing_num_cols + cat_cols].copy()\n",
    "\n",
    "    # One-hot for categoricals (drop_first to reduce collinearity; include NaN category)\n",
    "    X = pd.get_dummies(X, columns=cat_cols, dummy_na=True, drop_first=True)\n",
    "\n",
    "    # Strictly numeric\n",
    "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Drop columns that are entirely NaN\n",
    "    all_nan_cols = [c for c in X.columns if X[c].isna().all()]\n",
    "    if all_nan_cols:\n",
    "        X = X.drop(columns=all_nan_cols)\n",
    "\n",
    "    return X, y_cont, df  # df is the full original for summarization\n",
    "\n",
    "# ----------------------------\n",
    "# Model (Regressor)\n",
    "# ----------------------------\n",
    "class RiskRegressor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1)  # predict composite_risk_score âˆˆ [0,1]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_risk_regressor(X_train_df, y_train_cont, X_val_df, y_val_cont, epochs=120, lr=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[Regressor] Using device: {device}\")\n",
    "\n",
    "    # Safety / impute / align\n",
    "    for _df in [X_train_df, X_val_df]:\n",
    "        _df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_train_df = X_train_df.fillna(X_train_df.median(numeric_only=True))\n",
    "    X_val_df   = X_val_df.fillna(X_val_df.median(numeric_only=True))\n",
    "\n",
    "    all_nan_cols = list(set(\n",
    "        [c for c in X_train_df.columns if X_train_df[c].isna().all()] +\n",
    "        [c for c in X_val_df.columns   if X_val_df[c].isna().all()]\n",
    "    ))\n",
    "    if all_nan_cols:\n",
    "        X_train_df.drop(columns=all_nan_cols, inplace=True, errors=\"ignore\")\n",
    "        X_val_df.drop(columns=all_nan_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Align columns between train and val\n",
    "    X_val_df = X_val_df.reindex(columns=X_train_df.columns, fill_value=0)\n",
    "\n",
    "    X_train = torch.as_tensor(X_train_df.values.astype(np.float32), device=device)\n",
    "    X_val   = torch.as_tensor(X_val_df.values.astype(np.float32),   device=device)\n",
    "    y_train = torch.as_tensor(np.asarray(y_train_cont, dtype=np.float32).reshape(-1, 1), device=device)\n",
    "    y_val   = torch.as_tensor(np.asarray(y_val_cont,   dtype=np.float32).reshape(-1, 1), device=device)\n",
    "\n",
    "    model = RiskRegressor(input_size=X_train_df.shape[1]).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_train)\n",
    "        loss = criterion(pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                vpred = model(X_val)\n",
    "                vloss = criterion(vpred, y_val).item()\n",
    "            print(f\"[Regressor] Epoch {epoch:03d}/{epochs} | Train MSE: {loss.item():.5f} | Val MSE: {vloss:.5f}\")\n",
    "            if vloss < best_val:\n",
    "                best_val = vloss\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    print(\"[Regressor] Training completed. Best Val MSE:\", best_val)\n",
    "    return model, X_train_df.columns.tolist()\n",
    "\n",
    "def predict_patent_risk(model, X_df, feature_order):\n",
    "    \"\"\"Return clamped predictions in [0,1] for each row in X_df using feature_order.\"\"\"\n",
    "    X_use = X_df.reindex(columns=feature_order, fill_value=0).copy()\n",
    "    X_use.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_use = X_use.fillna(X_use.median(numeric_only=True))\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.as_tensor(X_use.values.astype(np.float32), device=device)).cpu().numpy().ravel()\n",
    "    pred = np.clip(pred, 0.0, 1.0)\n",
    "    return pred\n",
    "\n",
    "# ----------------------------\n",
    "# Summaries (Model-driven)\n",
    "# ----------------------------\n",
    "def summarize_from_model_predictions(df_full: pd.DataFrame, y_pred: np.ndarray, top_k=5, high_cut=0.66):\n",
    "    \"\"\"\n",
    "    Build the requested JSON using ONLY model predictions.\n",
    "    TC overall risk = weighted combination of mean predicted risk, pct of 'high' predicted,\n",
    "                      and reviewer-linked mean predicted risk.\n",
    "    \"\"\"\n",
    "    dfx = df_full.copy()\n",
    "    dfx[\"pred_score\"] = y_pred\n",
    "    dfx[\"pred_is_high\"] = dfx[\"pred_score\"] > high_cut\n",
    "\n",
    "    # Reviewer appearances (prefer reviewer_risk_contributions; fallback to linked_reviewers)\n",
    "    rows = []\n",
    "    for _, r in dfx.iterrows():\n",
    "        rlist = r.get(\"reviewer_risk_contributions\", [])\n",
    "        rid_list = []\n",
    "        if isinstance(rlist, list) and len(rlist) > 0:\n",
    "            rid_list = [rr.get(\"reviewer_id\") for rr in rlist if isinstance(rr, dict)]\n",
    "        elif isinstance(r.get(\"linked_reviewers\"), list):\n",
    "            rid_list = r.get(\"linked_reviewers\")\n",
    "        for rid in rid_list:\n",
    "            rows.append({\n",
    "                \"reviewer_id\": rid,\n",
    "                \"TC\": r.get(\"TC\"),\n",
    "                \"pred_score\": r.get(\"pred_score\", np.nan)\n",
    "            })\n",
    "    rev_df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"reviewer_id\", \"TC\", \"pred_score\"])\n",
    "\n",
    "    # TC-level aggregates (model-driven)\n",
    "    tc_grp = dfx.groupby(\"TC\", dropna=False).agg(\n",
    "        mean_pred=(\"pred_score\", \"mean\"),\n",
    "        pct_high_pred=(\"pred_is_high\", \"mean\"),\n",
    "        n_events=(\"patent_id\", \"count\")\n",
    "    )\n",
    "    if not rev_df.empty:\n",
    "        tc_rev = rev_df.groupby(\"TC\", dropna=False)[\"pred_score\"].mean().rename(\"reviewer_pred_in_tc\")\n",
    "        tc_grp = tc_grp.join(tc_rev, how=\"left\")\n",
    "    else:\n",
    "        tc_grp[\"reviewer_pred_in_tc\"] = np.nan\n",
    "    tc_grp[[\"reviewer_pred_in_tc\"]] = tc_grp[[\"reviewer_pred_in_tc\"]].fillna(0.0)\n",
    "\n",
    "    # Transparent weights (tune later or learn)\n",
    "    w_mean, w_pct, w_rev = 0.7, 0.2, 0.1\n",
    "    tc_grp[\"overall_tc_risk\"] = (\n",
    "        w_mean * tc_grp[\"mean_pred\"] +\n",
    "        w_pct  * tc_grp[\"pct_high_pred\"] +\n",
    "        w_rev  * tc_grp[\"reviewer_pred_in_tc\"]\n",
    "    )\n",
    "\n",
    "    tc_ranked = tc_grp.sort_values(\"overall_tc_risk\", ascending=False).reset_index()\n",
    "\n",
    "    # Build TC items with top reviewers (ranked by avg pred score in that TC)\n",
    "    out_tcs = []\n",
    "    for _, row in tc_ranked.head(top_k).iterrows():\n",
    "        tc = row[\"TC\"]\n",
    "        if not rev_df.empty and pd.notna(tc):\n",
    "            r_in_tc = rev_df[rev_df[\"TC\"] == tc].groupby(\"reviewer_id\")[\"pred_score\"].mean().reset_index()\n",
    "            r_in_tc = r_in_tc.sort_values(\"pred_score\", ascending=False).head(5)\n",
    "            top_reviewers_json = [\n",
    "                {\"reviewer_id\": rid, \"reviewer_overall_model\": float(score)}\n",
    "                for rid, score in zip(r_in_tc[\"reviewer_id\"], r_in_tc[\"pred_score\"])\n",
    "            ]\n",
    "        else:\n",
    "            top_reviewers_json = []\n",
    "\n",
    "        out_tcs.append({\n",
    "            \"TC\": None if pd.isna(tc) else tc,\n",
    "            \"overall_risk\": float(row[\"overall_tc_risk\"]),\n",
    "            \"decided_based_on\": {\n",
    "                \"mean_predicted_patent_risk\": float(row[\"mean_pred\"]),\n",
    "                \"pct_high_predicted_patents\": float(row[\"pct_high_pred\"]),\n",
    "                \"reviewer_pred_in_tc\": float(row[\"reviewer_pred_in_tc\"]),\n",
    "                \"weights\": {\"mean_pred\": 0.7, \"pct_high_pred\": 0.2, \"reviewer_pred\": 0.1},\n",
    "                \"n_events\": int(row[\"n_events\"]),\n",
    "            },\n",
    "            \"top_reviewers_in_tc\": top_reviewers_json\n",
    "        })\n",
    "\n",
    "    # Reviewer-level summary\n",
    "    out_reviewers = []\n",
    "    if not rev_df.empty:\n",
    "        rsum = rev_df.groupby(\"reviewer_id\").agg(\n",
    "            reviewer_overall_model=(\"pred_score\", \"mean\"),\n",
    "            n_events=(\"pred_score\", \"count\")\n",
    "        ).reset_index().sort_values(\"reviewer_overall_model\", ascending=False)\n",
    "        for _, r in rsum.head(top_k).iterrows():\n",
    "            out_reviewers.append({\n",
    "                \"reviewer_id\": r[\"reviewer_id\"],\n",
    "                \"reviewer_overall\": float(r[\"reviewer_overall_model\"]),\n",
    "                \"decided_based_on\": {\n",
    "                    \"mean_predicted_patent_risk\": float(r[\"reviewer_overall_model\"]),\n",
    "                    \"n_events\": int(r[\"n_events\"])\n",
    "                }\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"highest_risk_tcs\": out_tcs,\n",
    "        \"highest_risk_reviewers\": out_reviewers\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322777c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Regressor] Using device: cpu\n",
      "[Regressor] Epoch 020/120 | Train MSE: 61.07678 | Val MSE: 12.12106\n",
      "[Regressor] Epoch 040/120 | Train MSE: 16.66831 | Val MSE: 0.83267\n",
      "[Regressor] Epoch 060/120 | Train MSE: 10.77893 | Val MSE: 0.02783\n",
      "[Regressor] Epoch 080/120 | Train MSE: 5.49794 | Val MSE: 0.15558\n",
      "[Regressor] Epoch 100/120 | Train MSE: 3.53892 | Val MSE: 0.07307\n",
      "[Regressor] Epoch 120/120 | Train MSE: 2.66921 | Val MSE: 0.06928\n",
      "[Regressor] Training completed. Best Val MSE: 0.027831001207232475\n",
      "\n",
      "=== Model-driven High-Risk Summary ===\n",
      "{\n",
      "  \"highest_risk_tcs\": [\n",
      "    {\n",
      "      \"TC\": \"2190\",\n",
      "      \"overall_risk\": 0.11810915110824265,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.14774490892887115,\n",
      "        \"pct_high_predicted_patents\": 0.0,\n",
      "        \"reviewer_pred_in_tc\": 0.14687716348148952,\n",
      "        \"weights\": {\n",
      "          \"mean_pred\": 0.7,\n",
      "          \"pct_high_pred\": 0.2,\n",
      "          \"reviewer_pred\": 0.1\n",
      "        },\n",
      "        \"n_events\": 56\n",
      "      },\n",
      "      \"top_reviewers_in_tc\": [\n",
      "        {\n",
      "          \"reviewer_id\": \"R-17\",\n",
      "          \"reviewer_overall_model\": 0.1527419090270996\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-20\",\n",
      "          \"reviewer_overall_model\": 0.15030109882354736\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-15\",\n",
      "          \"reviewer_overall_model\": 0.14947978407144547\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-08\",\n",
      "          \"reviewer_overall_model\": 0.1494466761747996\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-01\",\n",
      "          \"reviewer_overall_model\": 0.1491696983575821\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"TC\": \"2170\",\n",
      "      \"overall_risk\": 0.10875097715323515,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.1360817551612854,\n",
      "        \"pct_high_predicted_patents\": 0.0,\n",
      "        \"reviewer_pred_in_tc\": 0.13493747050219243,\n",
      "        \"weights\": {\n",
      "          \"mean_pred\": 0.7,\n",
      "          \"pct_high_pred\": 0.2,\n",
      "          \"reviewer_pred\": 0.1\n",
      "        },\n",
      "        \"n_events\": 48\n",
      "      },\n",
      "      \"top_reviewers_in_tc\": [\n",
      "        {\n",
      "          \"reviewer_id\": \"R-04\",\n",
      "          \"reviewer_overall_model\": 0.14239487051963806\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-14\",\n",
      "          \"reviewer_overall_model\": 0.1393776684999466\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-13\",\n",
      "          \"reviewer_overall_model\": 0.13807781537373862\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-08\",\n",
      "          \"reviewer_overall_model\": 0.13791465759277344\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-09\",\n",
      "          \"reviewer_overall_model\": 0.1370496079325676\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"TC\": \"2400a\",\n",
      "      \"overall_risk\": 0.10819214281249553,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.13545329868793488,\n",
      "        \"pct_high_predicted_patents\": 0.0,\n",
      "        \"reviewer_pred_in_tc\": 0.13374832240825005,\n",
      "        \"weights\": {\n",
      "          \"mean_pred\": 0.7,\n",
      "          \"pct_high_pred\": 0.2,\n",
      "          \"reviewer_pred\": 0.1\n",
      "        },\n",
      "        \"n_events\": 48\n",
      "      },\n",
      "      \"top_reviewers_in_tc\": [\n",
      "        {\n",
      "          \"reviewer_id\": \"R-20\",\n",
      "          \"reviewer_overall_model\": 0.14319873601198196\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-06\",\n",
      "          \"reviewer_overall_model\": 0.13965540130933127\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-18\",\n",
      "          \"reviewer_overall_model\": 0.1387764811515808\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-14\",\n",
      "          \"reviewer_overall_model\": 0.13874571025371552\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-21\",\n",
      "          \"reviewer_overall_model\": 0.1379486471414566\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"TC\": \"2120\",\n",
      "      \"overall_risk\": 0.10812090264784323,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.13530804216861725,\n",
      "        \"pct_high_predicted_patents\": 0.0,\n",
      "        \"reviewer_pred_in_tc\": 0.13405277600159515,\n",
      "        \"weights\": {\n",
      "          \"mean_pred\": 0.7,\n",
      "          \"pct_high_pred\": 0.2,\n",
      "          \"reviewer_pred\": 0.1\n",
      "        },\n",
      "        \"n_events\": 59\n",
      "      },\n",
      "      \"top_reviewers_in_tc\": [\n",
      "        {\n",
      "          \"reviewer_id\": \"R-16\",\n",
      "          \"reviewer_overall_model\": 0.14205652475357056\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-08\",\n",
      "          \"reviewer_overall_model\": 0.14113284647464752\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-21\",\n",
      "          \"reviewer_overall_model\": 0.14036667346954346\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-06\",\n",
      "          \"reviewer_overall_model\": 0.13876527547836304\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-13\",\n",
      "          \"reviewer_overall_model\": 0.13770258852413722\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"TC\": \"3620\",\n",
      "      \"overall_risk\": 0.10759498387166899,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.13467296957969666,\n",
      "        \"pct_high_predicted_patents\": 0.0,\n",
      "        \"reviewer_pred_in_tc\": 0.13323905165881328,\n",
      "        \"weights\": {\n",
      "          \"mean_pred\": 0.7,\n",
      "          \"pct_high_pred\": 0.2,\n",
      "          \"reviewer_pred\": 0.1\n",
      "        },\n",
      "        \"n_events\": 35\n",
      "      },\n",
      "      \"top_reviewers_in_tc\": [\n",
      "        {\n",
      "          \"reviewer_id\": \"R-20\",\n",
      "          \"reviewer_overall_model\": 0.13901867469151816\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-06\",\n",
      "          \"reviewer_overall_model\": 0.13830697536468506\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-13\",\n",
      "          \"reviewer_overall_model\": 0.1382409930229187\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-18\",\n",
      "          \"reviewer_overall_model\": 0.13784696658452353\n",
      "        },\n",
      "        {\n",
      "          \"reviewer_id\": \"R-17\",\n",
      "          \"reviewer_overall_model\": 0.1371577779452006\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"highest_risk_reviewers\": [\n",
      "    {\n",
      "      \"reviewer_id\": \"R-04\",\n",
      "      \"reviewer_overall\": 0.1379650774154257,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.1379650774154257,\n",
      "        \"n_events\": 47\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"reviewer_id\": \"R-20\",\n",
      "      \"reviewer_overall\": 0.13634677994542005,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.13634677994542005,\n",
      "        \"n_events\": 41\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"reviewer_id\": \"R-16\",\n",
      "      \"reviewer_overall\": 0.136078981252817,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.136078981252817,\n",
      "        \"n_events\": 39\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"reviewer_id\": \"R-08\",\n",
      "      \"reviewer_overall\": 0.13581124799592154,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.13581124799592154,\n",
      "        \"n_events\": 49\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"reviewer_id\": \"R-02\",\n",
      "      \"reviewer_overall\": 0.13574078095995862,\n",
      "      \"decided_based_on\": {\n",
      "        \"mean_predicted_patent_risk\": 0.13574078095995862,\n",
      "        \"n_events\": 46\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Saved summary to: model_summary_high_risk.json\n"
     ]
    }
   ],
   "source": [
    "# === NN Risk Summary: Run Workflow ===\n",
    "\n",
    "# ---- Configuration ----\n",
    "args = {\n",
    "    \"input\": \"patent_events.json\",            # path to your JSON file\n",
    "    \"out\": \"model_summary_high_risk.json\",    # output file path\n",
    "    \"top_k\": 5,                               # number of top TCs/reviewers to report\n",
    "    \"epochs\": 120,                            # training epochs\n",
    "    \"lr\": 1e-3,                               # learning rate\n",
    "    \"high_cut\": 0.35,                         # threshold for \"predicted high\" patent\n",
    "    \"seed\": 42                                # random seed\n",
    "}\n",
    "\n",
    "# ---- Pipeline ----\n",
    "set_seeds(args[\"seed\"])\n",
    "\n",
    "# Load data\n",
    "with open(args[\"input\"], \"r\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare features/target\n",
    "X, y_cont, df_full = prepare_features(df)\n",
    "\n",
    "# Align y with X rows (in case of prior filtering); reset indices\n",
    "y_cont = y_cont.iloc[X.index].reset_index(drop=True)\n",
    "X = X.reset_index(drop=True)\n",
    "\n",
    "# Train/val split (deterministic 80/20 with the given seed)\n",
    "n = len(X)\n",
    "if n < 5:\n",
    "    raise ValueError(f\"Not enough rows to train a model (found {n}).\")\n",
    "idx = np.arange(n)\n",
    "rng = np.random.default_rng(args[\"seed\"])\n",
    "rng.shuffle(idx)\n",
    "split = int(0.8 * n)\n",
    "tr_idx, va_idx = idx[:split], idx[split:]\n",
    "X_train_df, X_val_df = X.iloc[tr_idx].copy(), X.iloc[va_idx].copy()\n",
    "y_train_cont, y_val_cont = y_cont.iloc[tr_idx].copy(), y_cont.iloc[va_idx].copy()\n",
    "\n",
    "# Train regressor\n",
    "model_reg, feat_order_reg = train_risk_regressor(\n",
    "    X_train_df, y_train_cont, X_val_df, y_val_cont,\n",
    "    epochs=args[\"epochs\"], lr=args[\"lr\"]\n",
    ")\n",
    "\n",
    "# Predict on ALL rows (current snapshot)\n",
    "y_pred_all = predict_patent_risk(model_reg, X, feat_order_reg)\n",
    "\n",
    "# Build the model-driven summary\n",
    "summary_json = summarize_from_model_predictions(\n",
    "    df_full, y_pred_all, top_k=args[\"top_k\"], high_cut=args[\"high_cut\"]\n",
    ")\n",
    "\n",
    "# Save + display\n",
    "safe_write_json(summary_json, args[\"out\"])\n",
    "print(\"\\n=== Model-driven High-Risk Summary ===\")\n",
    "print(json.dumps(summary_json, indent=2))\n",
    "print(f\"\\nSaved summary to: {args['out']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
